{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6a9f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aims\n",
    "import getAnswer\n",
    "\n",
    "ans = getAnswer.getOutput(aims.codeAim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "266698fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure, here is a program to demonstrate the working of the decision tree-based ID3 algorithm.\\n\\n```python\\nimport math\\n\\ndef entropy(data):\\n  \"\"\"\\n  Calculates the entropy of a dataset.\\n\\n  Args:\\n    data: A dataset.\\n\\n  Returns:\\n    The entropy of the dataset.\\n  \"\"\"\\n\\n  num_classes = len(data[0][-1])\\n  total_elements = len(data)\\n  entropy = 0\\n\\n  for class_ in range(num_classes):\\n    probability = data.count((None,) * len(data[0]) + (class_,)) / total_elements\\n    entropy -= probability * math.log2(probability)\\n\\n  return entropy\\n\\ndef information_gain(data, attribute):\\n  \"\"\"\\n  Calculates the information gain of a dataset given an attribute.\\n\\n  Args:\\n    data: A dataset.\\n    attribute: The attribute to calculate the information gain for.\\n\\n  Returns:\\n    The information gain of the dataset given the attribute.\\n  \"\"\"\\n\\n  entropy_of_data = entropy(data)\\n  entropy_of_attribute = 0\\n\\n  for value in data[attribute]:\\n    entropy_of_attribute += entropy(data[data[attribute] == value])\\n\\n  information_gain = entropy_of_data - entropy_of_attribute\\n\\n  return information_gain\\n\\ndef id3(data, attributes):\\n  \"\"\"\\n  Builds a decision tree from a dataset.\\n\\n  Args:\\n    data: A dataset.\\n    attributes: The attributes to use to build the decision tree.\\n\\n  Returns:\\n    The decision tree.\\n  \"\"\"\\n\\n  if len(attributes) == 0:\\n    return {None: data[-1]}\\n\\n  best_attribute = max(attributes, key=lambda attribute: information_gain(data, attribute))\\n  decision_tree = {best_attribute: {}}\\n\\n  for value in data[best_attribute]:\\n    decision_tree[best_attribute][value] = id3(data[data[best_attribute] == value], attributes.difference([best_attribute]))\\n\\n  return decision_tree\\n\\ndef classify(data, decision_tree):\\n  \"\"\"\\n  Classifies a sample using a decision tree.\\n\\n  Args:\\n    data: The sample to classify.\\n    decision_tree: The decision tree to use.\\n\\n  Returns:\\n    The class of the sample.\\n  \"\"\"\\n\\n  for attribute, value in decision_tree.items():\\n    if data[attribute] in value:\\n      return classify(data, value[data[attribute]])\\n\\n  return decision_tree[None]\\n\\ndef main():\\n  # Create a dataset.\\n  data = [\\n    (1, \\'A\\', \\'Yes\\'),\\n    (2, \\'B\\', \\'No\\'),\\n    (3, \\'A\\', \\'Yes\\'),\\n    (4, \\'B\\', \\'No\\'),\\n    (5, \\'A\\', \\'Yes\\')\\n  ]\\n\\n  # Create a list of attributes.\\n  attributes = [\\'age\\', \\'color\\']\\n\\n  # Build a decision tree.\\n  decision_tree = id3(data, attributes)\\n\\n  # Classify a new sample.\\n  new_sample = (6, \\'A\\', None)\\n  class_ = classify(new_sample, decision_tree)\\n\\n  # Print the class of the new sample.\\n  print(class_)\\n\\nif __name__ == \\'__main__\\':\\n  main()\\n```\\n\\nThis program will create a decision tree from the given dataset. The decision tree will be used to classify a new sample. The class of the new sample will be printed to the console.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d94714f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport math\\n\\ndef entropy(data):\\n  \"\"\"\\n  Calculates the entropy of a dataset.\\n\\n  Args:\\n    data: A dataset.\\n\\n  Returns:\\n    The entropy of the dataset.\\n  \"\"\"\\n\\n  num_classes = len(data[0][-1])\\n  total_elements = len(data)\\n  entropy = 0\\n\\n  for class_ in range(num_classes):\\n    probability = data.count((None,) * len(data[0]) + (class_,)) / total_elements\\n    entropy -= probability * math.log2(probability)\\n\\n  return entropy\\n\\ndef information_gain(data, attribute):\\n  \"\"\"\\n  Calculates the information gain of a dataset given an attribute.\\n\\n  Args:\\n    data: A dataset.\\n    attribute: The attribute to calculate the information gain for.\\n\\n  Returns:\\n    The information gain of the dataset given the attribute.\\n  \"\"\"\\n\\n  entropy_of_data = entropy(data)\\n  entropy_of_attribute = 0\\n\\n  for value in data[attribute]:\\n    entropy_of_attribute += entropy(data[data[attribute] == value])\\n\\n  information_gain = entropy_of_data - entropy_of_attribute\\n\\n  return information_gain\\n\\ndef id3(data, attributes):\\n  \"\"\"\\n  Builds a decision tree from a dataset.\\n\\n  Args:\\n    data: A dataset.\\n    attributes: The attributes to use to build the decision tree.\\n\\n  Returns:\\n    The decision tree.\\n  \"\"\"\\n\\n  if len(attributes) == 0:\\n    return {None: data[-1]}\\n\\n  best_attribute = max(attributes, key=lambda attribute: information_gain(data, attribute))\\n  decision_tree = {best_attribute: {}}\\n\\n  for value in data[best_attribute]:\\n    decision_tree[best_attribute][value] = id3(data[data[best_attribute] == value], attributes.difference([best_attribute]))\\n\\n  return decision_tree\\n\\ndef classify(data, decision_tree):\\n  \"\"\"\\n  Classifies a sample using a decision tree.\\n\\n  Args:\\n    data: The sample to classify.\\n    decision_tree: The decision tree to use.\\n\\n  Returns:\\n    The class of the sample.\\n  \"\"\"\\n\\n  for attribute, value in decision_tree.items():\\n    if data[attribute] in value:\\n      return classify(data, value[data[attribute]])\\n\\n  return decision_tree[None]\\n\\ndef main():\\n  # Create a dataset.\\n  data = [\\n    (1, \\'A\\', \\'Yes\\'),\\n    (2, \\'B\\', \\'No\\'),\\n    (3, \\'A\\', \\'Yes\\'),\\n    (4, \\'B\\', \\'No\\'),\\n    (5, \\'A\\', \\'Yes\\')\\n  ]\\n\\n  # Create a list of attributes.\\n  attributes = [\\'age\\', \\'color\\']\\n\\n  # Build a decision tree.\\n  decision_tree = id3(data, attributes)\\n\\n  # Classify a new sample.\\n  new_sample = (6, \\'A\\', None)\\n  class_ = classify(new_sample, decisi'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find given String in string\n",
    "start = ans.find(\"```\")+9\n",
    "\n",
    "end =ans[start:].find(\"```\")\n",
    "\n",
    "ans[start:end+1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
